{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install twitter \n",
    "!pip install NetworkX\n",
    "!pip install powerlaw\n",
    "!pip install string\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import requests\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "import string\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_tutti.csv')\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation.replace('#','')])\n",
    "    #text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    # Define the regular expression pattern to match words starting with \"#\"\n",
    "    pattern = re.compile(r\"\\B#\\w\\w+\\b\\s*\")\n",
    "\n",
    "    # Use the sub() function to replace matched patterns with an empty string\n",
    "    result = pattern.sub(\"\", text)\n",
    "\n",
    "    return result\n",
    "\n",
    "def remove_useless_words(text):\n",
    "    stop_words = set(stopwords.words('italian'))\n",
    "\n",
    "def combina(text):\n",
    "    comb=list(combinations(text, 2))\n",
    "    return comb\n",
    "\n",
    "#rimuoviamo dai tweet punteggiatura, hashtags e i tweet senza hashtags\n",
    "    \n",
    "df=df.drop_duplicates('tweet', keep='first')\n",
    "df['Tweet_punct'] = df['tweet'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df['Tweet_punct']=df['Tweet_punct'].apply(lambda x: remove_hashtags(x))\n",
    "\n",
    "\n",
    "df['#'] = df['hashtags'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df['#'] = df['#'].apply(lambda x: 'none' if len(x) == 0 else x)\n",
    "    \n",
    "#mask = df['#'].str.len() > 0\n",
    "#df = df[mask]\n",
    "\n",
    "\n",
    "#rimuoviamo dai tweet parole inutili e inferiori a lunghezza 3\n",
    "\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "\n",
    "tweets = [tweet.lower().split() for tweet in df['Tweet_punct']]\n",
    "tags = [t.lower().split() for t in df['#']]\n",
    "tweets = [[word for word in tweet_words if not word in stop_words] for tweet_words in tweets]\n",
    "tweets = [[word for word in tweet_words if len(word) >3] for tweet_words in tweets]\n",
    "\n",
    "\n",
    "#creiamo dataframe (df_bigram_counts) con qualsiasi bigramma in un tweet e relativo counts tra i tweet\n",
    "for i in range(0,len(tweets)):\n",
    "    if i==0:\n",
    "        comb=list(combinations(tweets[i], 2))\n",
    "    else:\n",
    "        comb[len(comb):]=list(combinations(tweets[i], 2))\n",
    "bigram_counts = collections.Counter(comb)\n",
    "\n",
    "df_bigram_counts = pd.DataFrame(bigram_counts.most_common(len(bigram_counts)), columns=['bigram', 'count'])\n",
    "\n",
    "\n",
    "#creiamo dataframe (df_bigram_tags)con bigramma e tutti i relativi hashtag tra i tweet\n",
    "\n",
    "comb_tag_df2=pd.DataFrame()\n",
    "comb_tag_df2['words']=tweets\n",
    "comb_tag_df2['tags']=tags\n",
    "\n",
    "combina=[]\n",
    "all_t=[]\n",
    "for w, t in comb_tag_df2.values:\n",
    "    for bi in list(combinations(w,2)):\n",
    "        combina.append(bi)\n",
    "        all_t.append(t)\n",
    "df_bigram_tags=pd.DataFrame()\n",
    "df_bigram_tags['bigram']=combina\n",
    "df_bigram_tags['tags']=all_t\n",
    "df_bigram_tags=df_bigram_tags.groupby(['bigram']).sum()\n",
    "\n",
    "\n",
    "#dataframe finale ordinato per i counts con bigramma e tags, togliamo i bigrammi comparsi in un solo tweet\n",
    "df_final=pd.merge(left=df_bigram_tags, right=df_bigram_counts, on='bigram')\n",
    "df_final.sort_values(by=['count'], ascending=False, inplace=True)\n",
    "\n",
    "mask = df_final['count'] > 1\n",
    "df_final = df_final[mask]\n",
    "\n",
    "df_final.reset_index(inplace=True, drop=True)\n",
    "\n",
    "def group_none(lst):\n",
    "    new_lst = []\n",
    "    none_count = 0\n",
    "    for item in lst:\n",
    "        if item == 'none':\n",
    "            none_count += 1\n",
    "        else:\n",
    "            new_lst.append(item)\n",
    "    if none_count > 0:\n",
    "        new_lst.append(f\"{none_count}none\")\n",
    "    return new_lst\n",
    "\n",
    "# tutti i tag None li riaggruppa specificando quanti sono\n",
    "df_final['tags'] = df_final['tags'].apply(group_none)\n",
    "\n",
    "df_final.to_csv('dataset_processato.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
